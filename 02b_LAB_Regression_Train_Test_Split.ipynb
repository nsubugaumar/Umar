{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "beb25a9b7f74ba8297b9ddc8cfce0e58572157eadb51d12df4cf574f713fc8b8"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Machine Learning Foundation\n\n## Course 2, Part b: Regression Setup, Train-test Split LAB \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction\n\nWe will be working with a data set based on [housing prices in Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). It was compiled for educational use to be a modernized and expanded alternative to the well-known Boston Housing dataset. This version of the data set has had some missing values filled for convenience.\n\nThere are an extensive number of features, so they've been described in the table below.\n\n### Predictor\n\n* SalePrice: The property's sale price in dollars. \n\n### Features\n\n* MoSold: Month Sold\n* YrSold: Year Sold   \n* SaleType: Type of sale\n* SaleCondition: Condition of sale\n* MSSubClass: The building class\n* MSZoning: The general zoning classification\n* ...\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['tqdm', 'seaborn', 'pandas', 'numpy', 'scikit-learn'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "## Question 1\n\n* Import the data using Pandas and examine the shape. There are 79 feature columns plus the predictor, the sale price (`SalePrice`). \n* There are three different types: integers (`int64`), floats (`float64`), and strings (`object`, categoricals). Examine how many there are of each data type. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n \nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n \npath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/data/Ames_Housing_Sales.csv\"\n \n#you will need to download the dataset; if you are running locally, please comment out the following \nawait download(path, \"Ames_Housing_Sales.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# Import pandas library\nimport pandas as pd\nimport numpy as np\n# Read the online file by the URL provides above, and assign it to variable \"df\"\n \ndata = pd.read_csv(\"Ames_Housing_Sales.csv\")\n \n# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndata.head(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The first 5 rows of the dataframe\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n0     856.0     854.0        0.0   NaN             3     1Fam       TA   \n1    1262.0       0.0        0.0   NaN             3     1Fam       TA   \n2     920.0     866.0        0.0   NaN             3     1Fam       TA   \n3     961.0     756.0        0.0   NaN             3     1Fam       Gd   \n4    1145.0    1053.0        0.0   NaN             4     1Fam       TA   \n\n  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n0           No       706.0         0.0  ...         0.0   Pave             8   \n1           Gd       978.0         0.0  ...         0.0   Pave             6   \n2           Mn       486.0         0.0  ...         0.0   Pave             6   \n3           No       216.0         0.0  ...         0.0   Pave             7   \n4           Av       655.0         0.0  ...         0.0   Pave             9   \n\n   TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemodAdd YrSold SalePrice  \n0        856.0    AllPub         0.0      2003         2003   2008  208500.0  \n1       1262.0    AllPub       298.0      1976         1976   2007  181500.0  \n2        920.0    AllPub         0.0      2001         2002   2008  223500.0  \n3        756.0    AllPub         0.0      1915         1970   2006  140000.0  \n4       1145.0    AllPub       192.0      2000         2000   2008  250000.0  \n\n[5 rows x 80 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>3SsnPorch</th>\n      <th>Alley</th>\n      <th>BedroomAbvGr</th>\n      <th>BldgType</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>Street</th>\n      <th>TotRmsAbvGrd</th>\n      <th>TotalBsmtSF</th>\n      <th>Utilities</th>\n      <th>WoodDeckSF</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>856.0</td>\n      <td>854.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1Fam</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>706.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Pave</td>\n      <td>8</td>\n      <td>856.0</td>\n      <td>AllPub</td>\n      <td>0.0</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>2008</td>\n      <td>208500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1262.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1Fam</td>\n      <td>TA</td>\n      <td>Gd</td>\n      <td>978.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Pave</td>\n      <td>6</td>\n      <td>1262.0</td>\n      <td>AllPub</td>\n      <td>298.0</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>2007</td>\n      <td>181500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920.0</td>\n      <td>866.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1Fam</td>\n      <td>TA</td>\n      <td>Mn</td>\n      <td>486.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Pave</td>\n      <td>6</td>\n      <td>920.0</td>\n      <td>AllPub</td>\n      <td>0.0</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>2008</td>\n      <td>223500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>961.0</td>\n      <td>756.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1Fam</td>\n      <td>Gd</td>\n      <td>No</td>\n      <td>216.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Pave</td>\n      <td>7</td>\n      <td>756.0</td>\n      <td>AllPub</td>\n      <td>0.0</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>2006</td>\n      <td>140000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1145.0</td>\n      <td>1053.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1Fam</td>\n      <td>TA</td>\n      <td>Av</td>\n      <td>655.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Pave</td>\n      <td>9</td>\n      <td>1145.0</td>\n      <td>AllPub</td>\n      <td>192.0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>2008</td>\n      <td>250000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 80 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "data.dtypes.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "object     43\nfloat64    21\nint64      16\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\n\nA significant challenge, particularly when dealing with data that have many columns, is ensuring each column gets encoded correctly. \n\nThis is particularly true with data columns that are ordered categoricals (ordinals) vs unordered categoricals. Unordered categoricals should be one-hot encoded, however this can significantly increase the number of features and creates features that are highly correlated with each other.\n\nDetermine how many total features would be present, relative to what currently exists, if all string (object) features are one-hot encoded. Recall that the total number of one-hot encoded columns is `n-1`, where `n` is the number of categories.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Select the object (string) columns\nmask = data.dtypes == object\ncategorical_cols = data.columns[mask]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "# Determine how many extra columns would be created\nnum_ohc_cols = (data[categorical_cols]\n                .apply(lambda x: x.nunique(dropna = False))\n                .sort_values(ascending=False))\n\n\n# No need to encode if there is only one value\nsmall_num_ohc_cols = num_ohc_cols.loc[num_ohc_cols>1]\n\n# Number of one-hot columns is one less than the number of categories\nsmall_num_ohc_cols -= 1\n\n# This is 215 columns, assuming the original ones are dropped. \n# This is quite a few extra columns!\nsmall_num_ohc_cols.sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "215"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Question 3\n\nLet's create a new data set where all of the above categorical features will be one-hot encoded. We can fit this data and see how it affects the results.\n\n* Used the dataframe `.copy()` method to create a completely separate copy of the dataframe for one-hot encoding\n* On this new dataframe, one-hot encode each of the appropriate columns and add it back to the dataframe. Be sure to drop the original column.\n* For the data that are not one-hot encoded, drop the columns that are string categoricals.\n\nFor the first step, numerically encoding the string categoricals, either Scikit-learn;s `LabelEncoder` or `DictVectorizer` can be used. However, the former is probably easier since it doesn't require specifying a numerical value for each category, and we are going to one-hot encode all of the numerical values anyway. (Can you think of a time when `DictVectorizer` might be preferred?)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n# Copy of the data\ndata_ohc = data.copy()\n\n# The encoders\nle = LabelEncoder()\nohc = OneHotEncoder()\n\nfor col in num_ohc_cols.index:\n    print(data_ohc[col])\n    # Integer encode the string categories\n    dat = le.fit_transform(data_ohc[col]).astype(int)\n    \n    # Remove the original column from the dataframe\n    data_ohc = data_ohc.drop(col, axis=1)\n\n    # One hot encode the data--this returns a sparse array\n    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n\n    # Create unique column names\n    n_cols = new_dat.shape[1]\n    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n\n    # Create the new dataframe\n    new_df = pd.DataFrame(new_dat.toarray(), \n                          index=data_ohc.index, \n                          columns=col_names)\n\n    # Append the new data to the dataframe\n    data_ohc = pd.concat([data_ohc, new_df], axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "0       CollgCr\n1       Veenker\n2       CollgCr\n3       Crawfor\n4       NoRidge\n         ...   \n1374    Gilbert\n1375     NWAmes\n1376    Crawfor\n1377      NAmes\n1378    Edwards\nName: Neighborhood, Length: 1379, dtype: object\n0       VinylSd\n1       MetalSd\n2       VinylSd\n3       Wd Shng\n4       VinylSd\n         ...   \n1374    VinylSd\n1375    Plywood\n1376    CmentBd\n1377    MetalSd\n1378    HdBoard\nName: Exterior2nd, Length: 1379, dtype: object\n0       VinylSd\n1       MetalSd\n2       VinylSd\n3       Wd Sdng\n4       VinylSd\n         ...   \n1374    VinylSd\n1375    Plywood\n1376    CemntBd\n1377    MetalSd\n1378    HdBoard\nName: Exterior1st, Length: 1379, dtype: object\n0        Norm\n1       Feedr\n2        Norm\n3        Norm\n4        Norm\n        ...  \n1374     Norm\n1375     Norm\n1376     Norm\n1377     Norm\n1378     Norm\nName: Condition1, Length: 1379, dtype: object\n0       WD\n1       WD\n2       WD\n3       WD\n4       WD\n        ..\n1374    WD\n1375    WD\n1376    WD\n1377    WD\n1378    WD\nName: SaleType, Length: 1379, dtype: object\n0       CompShg\n1       CompShg\n2       CompShg\n3       CompShg\n4       CompShg\n         ...   \n1374    CompShg\n1375    CompShg\n1376    CompShg\n1377    CompShg\n1378    CompShg\nName: RoofMatl, Length: 1379, dtype: object\n0       2Story\n1       1Story\n2       2Story\n3       2Story\n4       2Story\n         ...  \n1374    2Story\n1375    1Story\n1376    2Story\n1377    1Story\n1378    1Story\nName: HouseStyle, Length: 1379, dtype: object\n0       Norm\n1       Norm\n2       Norm\n3       Norm\n4       Norm\n        ... \n1374    Norm\n1375    Norm\n1376    Norm\n1377    Norm\n1378    Norm\nName: Condition2, Length: 1379, dtype: object\n0        Typ\n1        Typ\n2        Typ\n3        Typ\n4        Typ\n        ... \n1374     Typ\n1375    Min1\n1376     Typ\n1377     Typ\n1378     Typ\nName: Functional, Length: 1379, dtype: object\n0       Unf\n1       Unf\n2       Unf\n3       Unf\n4       Unf\n       ... \n1374    NaN\n1375    Rec\n1376    Unf\n1377    Rec\n1378    LwQ\nName: BsmtFinType2, Length: 1379, dtype: object\n0       Attchd\n1       Attchd\n2       Attchd\n3       Detchd\n4       Attchd\n         ...  \n1374    Attchd\n1375    Attchd\n1376    Attchd\n1377    Attchd\n1378    Attchd\nName: GarageType, Length: 1379, dtype: object\n0       GasA\n1       GasA\n2       GasA\n3       GasA\n4       GasA\n        ... \n1374    GasA\n1375    GasA\n1376    GasA\n1377    GasA\n1378    GasA\nName: Heating, Length: 1379, dtype: object\n0       GLQ\n1       ALQ\n2       GLQ\n3       ALQ\n4       GLQ\n       ... \n1374    NaN\n1375    ALQ\n1376    GLQ\n1377    GLQ\n1378    BLQ\nName: BsmtFinType1, Length: 1379, dtype: object\n0       NaN\n1        TA\n2        TA\n3        Gd\n4        TA\n       ... \n1374     TA\n1375     TA\n1376     Gd\n1377    NaN\n1378    NaN\nName: FireplaceQu, Length: 1379, dtype: object\n0        PConc\n1       CBlock\n2        PConc\n3       BrkTil\n4        PConc\n         ...  \n1374     PConc\n1375    CBlock\n1376     Stone\n1377    CBlock\n1378    CBlock\nName: Foundation, Length: 1379, dtype: object\n0       Gable\n1       Gable\n2       Gable\n3       Gable\n4       Gable\n        ...  \n1374    Gable\n1375    Gable\n1376    Gable\n1377      Hip\n1378    Gable\nName: RoofStyle, Length: 1379, dtype: object\n0        Normal\n1        Normal\n2        Normal\n3       Abnorml\n4        Normal\n         ...   \n1374     Normal\n1375     Normal\n1376     Normal\n1377     Normal\n1378     Normal\nName: SaleCondition, Length: 1379, dtype: object\n0        NaN\n1        NaN\n2        NaN\n3        NaN\n4        NaN\n        ... \n1374     NaN\n1375     NaN\n1376    Shed\n1377     NaN\n1378     NaN\nName: MiscFeature, Length: 1379, dtype: object\n0       RL\n1       RL\n2       RL\n3       RL\n4       RL\n        ..\n1374    RL\n1375    RL\n1376    RL\n1377    RL\n1378    RL\nName: MSZoning, Length: 1379, dtype: object\n0       Inside\n1          FR2\n2       Inside\n3       Corner\n4          FR2\n         ...  \n1374    Inside\n1375    Inside\n1376    Inside\n1377    Inside\n1378    Inside\nName: LotConfig, Length: 1379, dtype: object\n0        No\n1        Gd\n2        Mn\n3        No\n4        Av\n       ... \n1374    NaN\n1375     No\n1376     No\n1377     Mn\n1378     No\nName: BsmtExposure, Length: 1379, dtype: object\n0       Ex\n1       Ex\n2       Ex\n3       Gd\n4       Ex\n        ..\n1374    Ex\n1375    TA\n1376    Ex\n1377    Gd\n1378    Gd\nName: HeatingQC, Length: 1379, dtype: object\n0        Gd\n1        Gd\n2        Gd\n3        TA\n4        Gd\n       ... \n1374    NaN\n1375     Gd\n1376     TA\n1377     TA\n1378     TA\nName: BsmtQual, Length: 1379, dtype: object\n0       SBrkr\n1       SBrkr\n2       SBrkr\n3       SBrkr\n4       SBrkr\n        ...  \n1374    SBrkr\n1375    SBrkr\n1376    SBrkr\n1377    FuseA\n1378    SBrkr\nName: Electrical, Length: 1379, dtype: object\n0       1Fam\n1       1Fam\n2       1Fam\n3       1Fam\n4       1Fam\n        ... \n1374    1Fam\n1375    1Fam\n1376    1Fam\n1377    1Fam\n1378    1Fam\nName: BldgType, Length: 1379, dtype: object\n0       TA\n1       TA\n2       TA\n3       TA\n4       TA\n        ..\n1374    TA\n1375    TA\n1376    TA\n1377    TA\n1378    TA\nName: GarageCond, Length: 1379, dtype: object\n0         NaN\n1         NaN\n2         NaN\n3         NaN\n4         NaN\n        ...  \n1374      NaN\n1375    MnPrv\n1376    GdPrv\n1377      NaN\n1378      NaN\nName: Fence, Length: 1379, dtype: object\n0       TA\n1       TA\n2       TA\n3       TA\n4       TA\n        ..\n1374    TA\n1375    TA\n1376    TA\n1377    TA\n1378    TA\nName: GarageQual, Length: 1379, dtype: object\n0       Gd\n1       TA\n2       Gd\n3       Gd\n4       Gd\n        ..\n1374    TA\n1375    TA\n1376    Gd\n1377    Gd\n1378    TA\nName: KitchenQual, Length: 1379, dtype: object\n0       Lvl\n1       Lvl\n2       Lvl\n3       Lvl\n4       Lvl\n       ... \n1374    Lvl\n1375    Lvl\n1376    Lvl\n1377    Lvl\n1378    Lvl\nName: LandContour, Length: 1379, dtype: object\n0       NaN\n1       NaN\n2       NaN\n3       NaN\n4       NaN\n       ... \n1374    NaN\n1375    NaN\n1376    NaN\n1377    NaN\n1378    NaN\nName: PoolQC, Length: 1379, dtype: object\n0       Reg\n1       Reg\n2       IR1\n3       IR1\n4       IR1\n       ... \n1374    Reg\n1375    Reg\n1376    Reg\n1377    Reg\n1378    Reg\nName: LotShape, Length: 1379, dtype: object\n0       Gd\n1       TA\n2       Gd\n3       TA\n4       Gd\n        ..\n1374    TA\n1375    TA\n1376    Ex\n1377    TA\n1378    Gd\nName: ExterQual, Length: 1379, dtype: object\n0       BrkFace\n1           NaN\n2       BrkFace\n3           NaN\n4       BrkFace\n         ...   \n1374        NaN\n1375      Stone\n1376        NaN\n1377        NaN\n1378        NaN\nName: MasVnrType, Length: 1379, dtype: object\n0       TA\n1       TA\n2       TA\n3       TA\n4       TA\n        ..\n1374    TA\n1375    TA\n1376    Gd\n1377    TA\n1378    TA\nName: ExterCond, Length: 1379, dtype: object\n0        TA\n1        TA\n2        TA\n3        Gd\n4        TA\n       ... \n1374    NaN\n1375     TA\n1376     Gd\n1377     TA\n1378     TA\nName: BsmtCond, Length: 1379, dtype: object\n0       NaN\n1       NaN\n2       NaN\n3       NaN\n4       NaN\n       ... \n1374    NaN\n1375    NaN\n1376    NaN\n1377    NaN\n1378    NaN\nName: Alley, Length: 1379, dtype: object\n0       Y\n1       Y\n2       Y\n3       Y\n4       Y\n       ..\n1374    Y\n1375    Y\n1376    Y\n1377    Y\n1378    Y\nName: PavedDrive, Length: 1379, dtype: object\n0       Gtl\n1       Gtl\n2       Gtl\n3       Gtl\n4       Gtl\n       ... \n1374    Gtl\n1375    Gtl\n1376    Gtl\n1377    Gtl\n1378    Gtl\nName: LandSlope, Length: 1379, dtype: object\n0       RFn\n1       RFn\n2       RFn\n3       Unf\n4       RFn\n       ... \n1374    RFn\n1375    Unf\n1376    RFn\n1377    Unf\n1378    Fin\nName: GarageFinish, Length: 1379, dtype: object\n0       Y\n1       Y\n2       Y\n3       Y\n4       Y\n       ..\n1374    Y\n1375    Y\n1376    Y\n1377    Y\n1378    Y\nName: CentralAir, Length: 1379, dtype: object\n0       Pave\n1       Pave\n2       Pave\n3       Pave\n4       Pave\n        ... \n1374    Pave\n1375    Pave\n1376    Pave\n1377    Pave\n1378    Pave\nName: Street, Length: 1379, dtype: object\n0       AllPub\n1       AllPub\n2       AllPub\n3       AllPub\n4       AllPub\n         ...  \n1374    AllPub\n1375    AllPub\n1376    AllPub\n1377    AllPub\n1378    AllPub\nName: Utilities, Length: 1379, dtype: object\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "# Column difference is as calculated above\ndata_ohc.shape[1] - data.shape[1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "215"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "print(data.shape[1])\n\n# Remove the string columns from the dataframe\ndata = data.drop(num_ohc_cols.index, axis=1)\n\nprint(data.shape[1])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "80\n37\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "## Question 4\n\n* Create train and test splits of both data sets. To ensure the data gets split the same way, use the same `random_state` in each of the two splits.\n* For each data set, fit a basic linear regression model on the training data. \n* Calculate the mean squared error on both the train and test sets for the respective models. Which model produces smaller error on the test data and why?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\ny_col = 'SalePrice'\n\n# Split the data that is not one-hot encoded\nfeature_cols = [x for x in data.columns if x != y_col]\nX_data = data[feature_cols]\ny_data = data[y_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n                                                    test_size=0.3, random_state=42)\n# Split the data that is one-hot encoded\nfeature_cols = [x for x in data_ohc.columns if x != y_col]\nX_data_ohc = data_ohc[feature_cols]\ny_data_ohc = data_ohc[y_col]\n\nX_train_ohc, X_test_ohc, y_train_ohc, y_test_ohc = train_test_split(X_data_ohc, y_data_ohc, \n                                                    test_size=0.3, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "# Compare the indices to ensure they are identical\n(X_train_ohc.index == X_train.index).all()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "X_train",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLR = LinearRegression()\n\n# Storage for error values\nerror_df = list()\n\n# Data that have not been one-hot encoded\nLR = LR.fit(X_train, y_train)\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train, y_train_pred),\n                           'test' : mean_squared_error(y_test,  y_test_pred)},\n                           name='no enc'))\n\n# Data that have been one-hot encoded\nLR = LR.fit(X_train_ohc, y_train_ohc)\ny_train_ohc_pred = LR.predict(X_train_ohc)\ny_test_ohc_pred = LR.predict(X_test_ohc)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train_ohc, y_train_ohc_pred),\n                           'test' : mean_squared_error(y_test_ohc,  y_test_ohc_pred)},\n                          name='one-hot enc'))\n\n# Assemble the results\nerror_df = pd.concat(error_df, axis=1)\nerror_df",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Note that the error values on the one-hot encoded data are very different for the train and test data. In particular, the errors on the test data are much higher. Based on the lecture, this is because the one-hot encoded model is overfitting the data. We will learn how to deal with issues like this in the next lesson.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 5\n\nFor each of the data sets (one-hot encoded and not encoded):\n\n* Scale the all the non-hot encoded values using one of the following: `StandardScaler`, `MinMaxScaler`, `MaxAbsScaler`.\n* Compare the error calculated on the test sets\n\nBe sure to calculate the skew (to decide if a transformation should be done) and fit the scaler on *ONLY* the training data, but then apply it to both the train and test data identically.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Mute the setting wtih a copy warnings\npd.options.mode.chained_assignment = None",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\n\nscalers = {'standard': StandardScaler(),\n           'minmax': MinMaxScaler(),\n           'maxabs': MaxAbsScaler()}\n\ntraining_test_sets = {\n    'not_encoded': (X_train, y_train, X_test, y_test),\n    'one_hot_encoded': (X_train_ohc, y_train_ohc, X_test_ohc, y_test_ohc)}\n\n\n# Get the list of float columns, and the float data\n# so that we don't scale something we already scaled. \n# We're supposed to scale the original data each time\nmask = X_train.dtypes == float\nfloat_columns = X_train.columns[mask]\n\n# initialize model\nLR = LinearRegression()\n\n# iterate over all possible combinations and get the errors\nerrors = {}\nfor encoding_label, (_X_train, _y_train, _X_test, _y_test) in training_test_sets.items():\n    for scaler_label, scaler in scalers.items():\n        trainingset = _X_train.copy()  # copy because we dont want to scale this more than once.\n        testset = _X_test.copy()\n        trainingset[float_columns] = scaler.fit_transform(trainingset[float_columns])\n        testset[float_columns] = scaler.transform(testset[float_columns])\n        LR.fit(trainingset, _y_train)\n        predictions = LR.predict(testset)\n        key = encoding_label + ' - ' + scaler_label + 'scaling'\n        errors[key] = mean_squared_error(_y_test, predictions)\n\nerrors = pd.Series(errors)\nprint(errors.to_string())\nprint('-' * 80)\nfor key, error_val in errors.items():\n    print(key, error_val)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Question 6\n\nPlot predictions vs actual for one of the models.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nsns.set_context('talk')\nsns.set_style('ticks')\nsns.set_palette('dark')\n\nax = plt.axes()\n# we are going to use y_test, y_test_pred\nax.scatter(y_test, y_test_pred, alpha=.5)\n\nax.set(xlabel='Ground truth', \n       ylabel='Predictions',\n       title='Ames, Iowa House Price Predictions vs Truth, using Linear Regression');",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n### Machine Learning Foundation (C) 2020 IBM Corporation\n",
      "metadata": {}
    }
  ]
}